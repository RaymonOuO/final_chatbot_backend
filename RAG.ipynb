{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e373a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-community in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (0.3.22)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.6-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: transformers in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain) (0.3.55)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp39-cp39-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-4.0.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.19.2-cp39-cp39-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from chromadb) (0.21.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.71.0-cp39-cp39-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp39-cp39-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from chromadb) (3.10.14)\n",
      "Requirement already satisfied: httpx>=0.27.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
      "  Using cached starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: filelock in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from transformers) (0.29.2)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: sympy in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from build>=1.0.3->chromadb) (8.5.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.6.2)\n",
      "Requirement already satisfied: certifi in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.22.3)\n",
      "Requirement already satisfied: six>=1.9.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached wrapt-1.17.2-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting distro>=1.5.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: click>=8.0.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp39-cp39-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.5-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp39-cp39-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from importlib-resources->chromadb) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (2.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading chromadb-1.0.6-cp39-abi3-win_amd64.whl (18.2 MB)\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/18.2 MB 2.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.6/18.2 MB 3.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 2.4/18.2 MB 3.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.1/18.2 MB 3.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 4.5/18.2 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 5.8/18.2 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 6.6/18.2 MB 4.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 7.1/18.2 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 8.1/18.2 MB 4.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 9.7/18.2 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 11.0/18.2 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 12.6/18.2 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 14.2/18.2 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 16.3/18.2 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.6/18.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.2/18.2 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.6-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Downloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading grpcio-1.71.0-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.1/4.3 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.3 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 12.2 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.1.0-cp39-cp39-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.19.2-cp39-cp39-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/11.1 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.2/11.1 MB 12.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.1 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
      "Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
      "Downloading posthog-4.0.0-py2.py3-none-any.whl (92 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httptools-0.6.4-cp39-cp39-win_amd64.whl (89 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Downloading watchfiles-1.0.5-cp39-cp39-win_amd64.whl (292 kB)\n",
      "Downloading websockets-15.0.1-cp39-cp39-win_amd64.whl (176 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached wrapt-1.17.2-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53915 sha256=819796cffdf4e69048ce3492011778c86b83402896508b0c9cb92ac72e930011\n",
      "  Stored in directory: c:\\users\\raymonouo\\appdata\\local\\pip\\cache\\wheels\\f7\\02\\64\\d541eac67ec459309d1fb19e727f58ecf7ffb4a8bf42d4cfe5\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, flatbuffers, durationpy, wrapt, websockets, shellingham, pyreadline3, pyproject_hooks, pyasn1, opentelemetry-util-http, opentelemetry-proto, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, googleapis-common-protos, distro, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-exporter-otlp-proto-common, markdown-it-py, humanfriendly, deprecated, build, rich, opentelemetry-api, google-auth, fastapi, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chroma-hnswlib-0.7.6 chromadb-1.0.6 coloredlogs-15.0.1 deprecated-1.2.18 distro-1.9.0 durationpy-0.9 fastapi-0.115.9 flatbuffers-25.2.10 google-auth-2.39.0 googleapis-common-protos-1.70.0 grpcio-1.71.0 httptools-0.6.4 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-32.0.1 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.19.2 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 posthog-4.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-14.0.0 rsa-4.9.1 shellingham-1.5.4 starlette-0.45.3 typer-0.15.2 uvicorn-0.34.2 watchfiles-1.0.5 websockets-15.0.1 wrapt-1.17.2\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from sentence-transformers) (2.3.1)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from sentence-transformers) (0.29.2)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.2.1-cp39-cp39-win_amd64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: colorama in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\dev\\anaconda3\\envs\\agent\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Downloading pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 17.1 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "   ---------------------------------------- 0.0/11.2 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 4.5/11.2 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.7/11.2 MB 24.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.2/11.2 MB 24.9 MB/s eta 0:00:00\n",
      "Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, pypdf, Pillow, joblib, scikit-learn, sentence-transformers\n",
      "Successfully installed Pillow-11.2.1 joblib-1.4.2 pypdf-5.4.0 scikit-learn-1.6.1 scipy-1.13.1 sentence-transformers-4.1.0 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "# Create a new conda environment named 'rag'\n",
    "!conda create -n rag python=3.9 -y\n",
    "\n",
    "# Activate the environment\n",
    "!conda activate rag\n",
    "\n",
    "# Install PyTorch with CUDA support (adjust cuda version if needed)\n",
    "!conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y\n",
    "\n",
    "# Install basic dependencies\n",
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install bitsandbytes\n",
    "!pip install sentencepiece\n",
    "!pip install fastapi\n",
    "!pip install uvicorn\n",
    "!pip install pydantic\n",
    "!pip install peft\n",
    "\n",
    "# Install LangChain, ChromaDB and other RAG-related packages\n",
    "!pip install langchain\n",
    "!pip install chromadb\n",
    "!pip install sentence-transformers\n",
    "!pip install pypdf\n",
    "!pip install langchain-community\n",
    "\n",
    "# Install PDF processing libraries\n",
    "!pip install pdfminer.six\n",
    "!pip install pymupdf\n",
    "\n",
    "# Install optional but useful packages\n",
    "!pip install tqdm\n",
    "!pip install ipywidgets\n",
    "!pip install jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4dd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf1ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "PDF_DIRECTORY = \"books\"  # Directory containing your PDF documents\n",
    "CHROMA_DB_DIRECTORY = \"chroma_db\"         # Directory to store ChromaDB\n",
    "CHUNK_SIZE = 1000                         # Text chunk size for splitting documents\n",
    "CHUNK_OVERLAP = 200                       # Overlap between chunks\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BASE_MODEL_PATH = \"meta-llama/Llama-3.2-1B\"  # Base model\n",
    "PEFT_MODEL_PATH = \"mental_health_chat_llm\"  # PEFT adapter path\n",
    "MAX_NEW_TOKENS = 256                        # Max new tokens to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7f7db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(pdf_directory):\n",
    "    \"\"\"\n",
    "    Load PDF documents from a specified directory.\n",
    "    \n",
    "    Args:\n",
    "        pdf_directory (str): Path to directory containing PDF files\n",
    "        \n",
    "    Returns:\n",
    "        list: List of loaded documents\n",
    "    \"\"\"\n",
    "    print(\"Loading PDF documents...\")\n",
    "    loader = DirectoryLoader(pdf_directory, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "    return documents\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"\n",
    "    Split documents into chunks for better retrieval.\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of documents to split\n",
    "        \n",
    "    Returns:\n",
    "        list: List of document chunks\n",
    "    \"\"\"\n",
    "    print(\"Splitting documents into chunks...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split into {len(chunks)} chunks\")\n",
    "    return chunks\n",
    "\n",
    "def create_vector_store(chunks):\n",
    "    \"\"\"\n",
    "    Create a ChromaDB vector store from document chunks.\n",
    "    \n",
    "    Args:\n",
    "        chunks (list): List of document chunks\n",
    "        \n",
    "    Returns:\n",
    "        Chroma: ChromaDB vector store\n",
    "    \"\"\"\n",
    "    print(\"Creating embeddings and vector store...\")\n",
    "    # Using a lightweight embedding model\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={\"device\": DEVICE}\n",
    "    )\n",
    "    \n",
    "    # Create or load the vector store\n",
    "    if os.path.exists(CHROMA_DB_DIRECTORY):\n",
    "        print(\"Loading existing ChromaDB...\")\n",
    "        vector_store = Chroma(\n",
    "            persist_directory=CHROMA_DB_DIRECTORY,\n",
    "            embedding_function=embedding_model\n",
    "        )\n",
    "    else:\n",
    "        print(\"Creating new ChromaDB...\")\n",
    "        vector_store = Chroma.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=embedding_model,\n",
    "            persist_directory=CHROMA_DB_DIRECTORY\n",
    "        )\n",
    "        vector_store.persist()\n",
    "    \n",
    "    print(\"Vector store created successfully\")\n",
    "    return vector_store\n",
    "\n",
    "def load_peft_model():\n",
    "    \"\"\"\n",
    "    Load the PEFT fine-tuned Llama model.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Tokenizer and model\n",
    "    \"\"\"\n",
    "    print(\"Loading PEFT fine-tuned model...\")\n",
    "    \n",
    "    # Load tokenizer from base model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "    \n",
    "    # Enable padding on the right side\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    \n",
    "    # Add special tokens if they don't exist\n",
    "    special_tokens = {\n",
    "        \"pad_token\": \"<PAD>\",\n",
    "        \"eos_token\": \"</s>\",\n",
    "        \"bos_token\": \"<s>\"\n",
    "    }\n",
    "    \n",
    "    for token_type, token in special_tokens.items():\n",
    "        if getattr(tokenizer, token_type) is None:\n",
    "            tokenizer.add_special_tokens({token_type: token})\n",
    "    \n",
    "    # Load base model\n",
    "    print(f\"Loading base model from {BASE_MODEL_PATH}...\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL_PATH,\n",
    "        torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32,\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    \n",
    "    # Load PEFT adapter on top of base model\n",
    "    print(f\"Loading PEFT adapter from {PEFT_MODEL_PATH}...\")\n",
    "    model = PeftModel.from_pretrained(\n",
    "        base_model,\n",
    "        PEFT_MODEL_PATH,\n",
    "        torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # Resize token embeddings if needed\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    print(f\"PEFT model loaded successfully (device: {DEVICE})\")\n",
    "    return tokenizer, model\n",
    "\n",
    "def setup_rag_pipeline(vector_store, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Set up the RAG pipeline integrating the vector store and language model.\n",
    "    \n",
    "    Args:\n",
    "        vector_store (Chroma): ChromaDB vector store\n",
    "        tokenizer: Tokenizer for the language model\n",
    "        model: Fine-tuned language model\n",
    "        \n",
    "    Returns:\n",
    "        function: query_function that can process user queries with RAG\n",
    "    \"\"\"\n",
    "    print(\"Setting up RAG pipeline...\")\n",
    "    \n",
    "    # Create a retriever from the vector store\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3}  # Retrieve top 3 most relevant documents\n",
    "    )\n",
    "    \n",
    "    # Create a text generation pipeline with correct parameters\n",
    "    # IMPORTANT: We specify max_new_tokens instead of max_length\n",
    "    generation_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=MAX_NEW_TOKENS,  # This is the key parameter\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    def query_rag_system(query, chat_history=None):\n",
    "        \"\"\"\n",
    "        Process a user query using the RAG system.\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            chat_history (list, optional): Previous conversation history\n",
    "            \n",
    "        Returns:\n",
    "            str: Generated response\n",
    "        \"\"\"\n",
    "        # Retrieve relevant documents\n",
    "        retrieved_docs = retriever.get_relevant_documents(query)\n",
    "        \n",
    "        # Format the context from retrieved documents\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "        \n",
    "        # Prepare the prompt with retrieved context\n",
    "        if chat_history:\n",
    "            # Format chat history if available\n",
    "            history_text = \"\\n\".join([f\"User: {q}\\nAssistant: {a}\" for q, a in chat_history])\n",
    "            prompt = f\"\"\"Context information from mental health resources:\n",
    "{context}\n",
    "\n",
    "Previous conversation:\n",
    "{history_text}\n",
    "\n",
    "User: {query}\n",
    "Assistant:\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"Context information from mental health resources:\n",
    "{context}\n",
    "\n",
    "User: {query}\n",
    "Assistant:\"\"\"\n",
    "        \n",
    "        # Generate response with fixed parameters\n",
    "        # Using return_full_text=False to only get the new tokens\n",
    "        response = generation_pipeline(\n",
    "            prompt, \n",
    "            return_full_text=False,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )[0][\"generated_text\"]\n",
    "        \n",
    "        return response.strip()\n",
    "    \n",
    "    print(\"RAG pipeline setup complete\")\n",
    "    return query_rag_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dad4331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to set up and run the mental health counseling RAG system.\n",
    "    \"\"\"\n",
    "    # Load and process PDF documents\n",
    "    documents = load_documents(PDF_DIRECTORY)\n",
    "    chunks = split_documents(documents)\n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = create_vector_store(chunks)\n",
    "    \n",
    "    # Load PEFT fine-tuned model\n",
    "    tokenizer, model = load_peft_model()\n",
    "    \n",
    "    # Set up RAG pipeline with fixed parameters\n",
    "    query_function = setup_rag_pipeline(vector_store, tokenizer, model)\n",
    "    \n",
    "    # Example usage\n",
    "    sample_query = \"I've been feeling anxious about my future lately. What can I do?\"\n",
    "    response = query_function(sample_query)\n",
    "    print(\"\\nSample Query:\", sample_query)\n",
    "    print(\"Response:\", response)\n",
    "    \n",
    "    # Interactive mode for testing\n",
    "    print(\"\\nEnter 'quit' to exit\")\n",
    "    chat_history = []\n",
    "    while True:\n",
    "        user_input = input(\"\\nYour question: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        response = query_function(user_input, chat_history)\n",
    "        print(\"Mental Health Assistant:\", response)\n",
    "        \n",
    "        # Update chat history\n",
    "        chat_history.append((user_input, response))\n",
    "        if len(chat_history) > 5:  # Keep only the last 5 exchanges\n",
    "            chat_history = chat_history[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2855e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF documents...\n",
      "Loaded 261 documents\n",
      "Splitting documents into chunks...\n",
      "Split into 459 chunks\n",
      "Creating embeddings and vector store...\n",
      "Loading existing ChromaDB...\n",
      "Vector store created successfully\n",
      "Loading PEFT fine-tuned model...\n",
      "Loading base model from meta-llama/Llama-3.2-1B...\n",
      "Loading PEFT adapter from mental_health_chat_llm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "Device set to use cuda:0\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT model loaded successfully (device: cuda)\n",
      "Setting up RAG pipeline...\n",
      "RAG pipeline setup complete\n",
      "\n",
      "Sample Query: I've been feeling anxious about my future lately. What can I do?\n",
      "Response: It is normal to feel anxious about the future.  Sometimes \n",
      "anxiety may be useful and help us to motivate us to do things that are \n",
      "important to us.  Anxiety is usually short-term, but sometimes it may \n",
      "be too much.  We can learn to manage anxiety so that it does not get \n",
      "in the way of our daily activities and enjoyment of life.  Anxiety is \n",
      "usually associated with a fear of failure, loss, or abandonment.  The \n",
      "first step in managing anxiety is to identify the source of this fear. \n",
      "Once the source of the fear is identified, the anxiety associated with \n",
      "that source can be reduced.  We can learn new ways to cope with the \n",
      "fear and replace it with a more positive and realistic thought.  This \n",
      "may be done by: \n",
      "/g120/g3Identifying the thoughts and feelings that are associated with the \n",
      "anxiety (sometimes it is helpful to write these thoughts and feelings \n",
      "down on a list). \n",
      "/g120/g3Identifying any irrational thoughts that may be contributing to \n",
      "the anxiety.  Irrational thoughts are often associated with a negative \n",
      "thought pattern.  For example, if I think I’m going to fail, that may \n",
      "be true, but if I think I\n",
      "\n",
      "Enter 'quit' to exit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec71a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
